f2 <- predict(fit_f2, newdata = data.frame(t = t))
d2 <- d1 - f2
return(list(f0 = f0, f1 = f1, f2 = f2, d2 = d2))
}
#########################
# 2. Tiện ích hỗ trợ
#########################
scale_minmax <- function(x) {
min_x <- min(x, na.rm = TRUE)
max_x <- max(x, na.rm = TRUE)
scaled <- (x - min_x) / (max_x - min_x)
list(scaled = scaled, min = min_x, max = max_x)
}
create_lstm_data <- function(series, lag = 10L) {
n <- length(series)
num_samples <- n - lag
X <- array(NA, dim = c(num_samples, lag, 1))
y <- array(NA, dim = c(num_samples))
for (i in 1:num_samples) {
X[i, , 1] <- series[i:(i + lag - 1)]
y[i] <- series[i + lag]
}
list(X = X, y = y)
}
build_lstm_model <- function(input_shape = c(10L, 1L)) {
model <- keras_model_sequential()
model %>%
layer_lstm(units = 64, input_shape = input_shape, return_sequences = TRUE) %>%
layer_lstm(units = 128, return_sequences = TRUE) %>%
layer_lstm(units = 128) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 1, activation = "relu")
return(model)
}
train_predict_lstm <- function(scaled_series, lag = 10L, horizon = 30L, epochs = 100, batch_size = 32) {
data <- create_lstm_data(scaled_series, lag)
X <- data$X
y <- data$y
model <- build_lstm_model(input_shape = c(lag, 1))
model %>% compile(loss = "mean_squared_error", optimizer = optimizer_adam())
early_stop <- callback_early_stopping(
monitor = "loss",
patience = 10,
restore_best_weights = TRUE
)
model %>% fit(
x = X,
y = y,
epochs = epochs,
batch_size = batch_size,
verbose = 1,
callbacks = list(early_stop)
)
preds <- numeric(horizon)
last_seq <- tail(scaled_series, lag)
for (i in 1:horizon) {
input_seq <- array(last_seq, dim = c(1L, lag, 1L))
input_seq <- tf$cast(input_seq, dtype = tf$float32)
pred <- as.numeric(model$predict(input_seq))
preds[i] <- pred
last_seq <- c(last_seq[-1], pred)
}
return(preds)
}
#########################
# 3. Bắt đầu triển khai mô hình DLWR-LSTM
#########################
# Dữ liệu đầu vào
raw_series <- as.numeric(training_data$vnindex_close)
decomp <- DLWR_decompose(raw_series, spans = c(0.3, 0.3, 0.3), degree = 2)
# Số bước dự báo
forecast_horizon <- as.integer(nrow(test_data))
# Khởi tạo danh sách kết quả
preds_components <- list()
# Huấn luyện và dự báo từng thành phần DLWR bằng LSTM riêng
for (name in c("f0", "f1", "f2", "d2")) {
comp <- decomp[[name]]
scaled <- scale_minmax(comp)
pred_scaled <- train_predict_lstm(
scaled_series = scaled$scaled,
lag = 10L,
horizon = forecast_horizon,
epochs = 100,
batch_size = 32
)
preds_components[[name]] <- pred_scaled * (scaled$max - scaled$min) + scaled$min
}
reticulate::py_last_error()
#########################
# 1. Hàm phân tách DLWR
#########################
DLWR_decompose <- function(R, spans = c(0.3, 0.3, 0.3), degree = 2) {
n <- length(R)
t <- seq_len(n)
fit_f0 <- loess(R ~ t, span = spans[1], degree = degree)
f0 <- predict(fit_f0, newdata = data.frame(t = t))
d0 <- R - f0
fit_f1 <- loess(d0 ~ t, span = spans[2], degree = degree)
f1 <- predict(fit_f1, newdata = data.frame(t = t))
d1 <- d0 - f1
fit_f2 <- loess(d1 ~ t, span = spans[3], degree = degree)
f2 <- predict(fit_f2, newdata = data.frame(t = t))
d2 <- d1 - f2
return(list(f0 = f0, f1 = f1, f2 = f2, d2 = d2))
}
#########################
# 2. Tiện ích hỗ trợ
#########################
scale_minmax <- function(x) {
min_x <- min(x, na.rm = TRUE)
max_x <- max(x, na.rm = TRUE)
scaled <- (x - min_x) / (max_x - min_x)
list(scaled = scaled, min = min_x, max = max_x)
}
create_lstm_data <- function(series, lag = 10L) {
n <- length(series)
num_samples <- n - lag
X <- array(NA, dim = c(num_samples, lag, 1))
y <- array(NA, dim = c(num_samples))
for (i in 1:num_samples) {
X[i, , 1] <- series[i:(i + lag - 1)]
y[i] <- series[i + lag]
}
list(X = X, y = y)
}
build_lstm_model <- function(input_shape = c(10L, 1L)) {
model <- keras_model_sequential()
model$add(layer_lstm(units = 64, input_shape = input_shape, return_sequences = TRUE))
model$add(layer_lstm(units = 128, return_sequences = TRUE))
model$add(layer_lstm(units = 128))
model$add(layer_dense(units = 128, activation = "relu"))
model$add(layer_dropout(rate = 0.2))
model$add(layer_dense(units = 1, activation = "relu"))
return(model)
}
train_predict_lstm <- function(scaled_series, lag = 10L, horizon = 30L, epochs = 100, batch_size = 32) {
data <- create_lstm_data(scaled_series, lag)
X <- data$X
y <- data$y
model <- build_lstm_model(input_shape = c(lag, 1))
model %>% compile(loss = "mean_squared_error", optimizer = optimizer_adam())
early_stop <- callback_early_stopping(
monitor = "loss",
patience = 10,
restore_best_weights = TRUE
)
model %>% fit(
x = X,
y = y,
epochs = epochs,
batch_size = batch_size,
verbose = 1,
callbacks = list(early_stop)
)
preds <- numeric(horizon)
last_seq <- tail(scaled_series, lag)
for (i in 1:horizon) {
input_seq <- array(last_seq, dim = c(1L, lag, 1L))
input_seq <- tf$cast(input_seq, dtype = tf$float32)
pred <- as.numeric(model$predict(input_seq))
preds[i] <- pred
last_seq <- c(last_seq[-1], pred)
}
return(preds)
}
#########################
# 3. Bắt đầu triển khai mô hình DLWR-LSTM
#########################
# Dữ liệu đầu vào
raw_series <- as.numeric(training_data$vnindex_close)
decomp <- DLWR_decompose(raw_series, spans = c(0.3, 0.3, 0.3), degree = 2)
# Số bước dự báo
forecast_horizon <- as.integer(nrow(test_data))
# Khởi tạo danh sách kết quả
preds_components <- list()
# Huấn luyện và dự báo từng thành phần DLWR bằng LSTM riêng
for (name in c("f0", "f1", "f2", "d2")) {
comp <- decomp[[name]]
scaled <- scale_minmax(comp)
pred_scaled <- train_predict_lstm(
scaled_series = scaled$scaled,
lag = 10L,
horizon = forecast_horizon,
epochs = 100,
batch_size = 32
)
preds_components[[name]] <- pred_scaled * (scaled$max - scaled$min) + scaled$min
}
#########################
# 1. Hàm phân tách DLWR
#########################
DLWR_decompose <- function(R, spans = c(0.3, 0.3, 0.3), degree = 2) {
n <- length(R)
t <- seq_len(n)
fit_f0 <- loess(R ~ t, span = spans[1], degree = degree)
f0 <- predict(fit_f0, newdata = data.frame(t = t))
d0 <- R - f0
fit_f1 <- loess(d0 ~ t, span = spans[2], degree = degree)
f1 <- predict(fit_f1, newdata = data.frame(t = t))
d1 <- d0 - f1
fit_f2 <- loess(d1 ~ t, span = spans[3], degree = degree)
f2 <- predict(fit_f2, newdata = data.frame(t = t))
d2 <- d1 - f2
return(list(f0 = f0, f1 = f1, f2 = f2, d2 = d2))
}
#########################
# 2. Tiện ích hỗ trợ
#########################
scale_minmax <- function(x) {
min_x <- min(x, na.rm = TRUE)
max_x <- max(x, na.rm = TRUE)
scaled <- (x - min_x) / (max_x - min_x)
list(scaled = scaled, min = min_x, max = max_x)
}
create_lstm_data <- function(series, lag = 10L) {
n <- length(series)
num_samples <- n - lag
X <- array(NA, dim = c(num_samples, lag, 1))
y <- array(NA, dim = c(num_samples))
for (i in 1:num_samples) {
X[i, , 1] <- series[i:(i + lag - 1)]
y[i] <- series[i + lag]
}
list(X = X, y = y)
}
build_lstm_model <- function(input_shape = c(10L, 1L)) {
model <- keras_model_sequential()
model$add(layer_lstm(units = 64, input_shape = input_shape, return_sequences = TRUE))
model$add(layer_lstm(units = 128, return_sequences = TRUE))
model$add(layer_lstm(units = 128))
model$add(layer_dense(units = 128, activation = "relu"))
model$add(layer_dropout(rate = 0.2))
model$add(layer_dense(units = 1, activation = "relu"))
return(model)
}
train_predict_lstm <- function(scaled_series, lag = 10L, horizon = 30L, epochs = 100, batch_size = 32) {
data <- create_lstm_data(scaled_series, lag)
X <- data$X
y <- data$y
model <- build_lstm_model(input_shape = c(lag, 1))
model$compile(
loss = "mean_squared_error",
optimizer = keras$optimizers$Adam()
)
early_stop <- callback_early_stopping(
monitor = "loss",
patience = 10,
restore_best_weights = TRUE
)
model$fit(
x = X,
y = y,
epochs = 100,
batch_size = 32,
callbacks = list(early_stop)
)
preds <- numeric(horizon)
last_seq <- tail(scaled_series, lag)
for (i in 1:horizon) {
input_seq <- array(last_seq, dim = c(1L, lag, 1L))
input_seq <- tf$cast(input_seq, dtype = tf$float32)
pred <- as.numeric(model$predict(input_seq))
preds[i] <- pred
last_seq <- c(last_seq[-1], pred)
}
return(preds)
}
#########################
# 3. Bắt đầu triển khai mô hình DLWR-LSTM
#########################
# Dữ liệu đầu vào
raw_series <- as.numeric(training_data$vnindex_close)
decomp <- DLWR_decompose(raw_series, spans = c(0.3, 0.3, 0.3), degree = 2)
# Số bước dự báo
forecast_horizon <- as.integer(nrow(test_data))
# Khởi tạo danh sách kết quả
preds_components <- list()
# Huấn luyện và dự báo từng thành phần DLWR bằng LSTM riêng
for (name in c("f0", "f1", "f2", "d2")) {
comp <- decomp[[name]]
scaled <- scale_minmax(comp)
pred_scaled <- train_predict_lstm(
scaled_series = scaled$scaled,
lag = 10L,
horizon = forecast_horizon,
epochs = 100,
batch_size = 32
)
preds_components[[name]] <- pred_scaled * (scaled$max - scaled$min) + scaled$min
}
#########################
# 1. Hàm phân tách DLWR
#########################
DLWR_decompose <- function(R, spans = c(0.3, 0.3, 0.3), degree = 2) {
n <- length(R)
t <- seq_len(n)
fit_f0 <- loess(R ~ t, span = spans[1], degree = degree)
f0 <- predict(fit_f0, newdata = data.frame(t = t))
d0 <- R - f0
fit_f1 <- loess(d0 ~ t, span = spans[2], degree = degree)
f1 <- predict(fit_f1, newdata = data.frame(t = t))
d1 <- d0 - f1
fit_f2 <- loess(d1 ~ t, span = spans[3], degree = degree)
f2 <- predict(fit_f2, newdata = data.frame(t = t))
d2 <- d1 - f2
return(list(f0 = f0, f1 = f1, f2 = f2, d2 = d2))
}
#########################
# 2. Tiện ích hỗ trợ
#########################
scale_minmax <- function(x) {
min_x <- min(x, na.rm = TRUE)
max_x <- max(x, na.rm = TRUE)
scaled <- (x - min_x) / (max_x - min_x)
list(scaled = scaled, min = min_x, max = max_x)
}
create_lstm_data <- function(series, lag = 10L) {
n <- length(series)
num_samples <- n - lag
X <- array(NA, dim = c(num_samples, lag, 1))
y <- array(NA, dim = c(num_samples))
for (i in 1:num_samples) {
X[i, , 1] <- series[i:(i + lag - 1)]
y[i] <- series[i + lag]
}
list(X = X, y = y)
}
build_lstm_model <- function(input_shape = c(10L, 1L)) {
model <- keras_model_sequential()
model$add(layer_lstm(units = 64, input_shape = input_shape, return_sequences = TRUE))
model$add(layer_lstm(units = 128, return_sequences = TRUE))
model$add(layer_lstm(units = 128))
model$add(layer_dense(units = 128, activation = "relu"))
model$add(layer_dropout(rate = 0.2))
model$add(layer_dense(units = 1, activation = "relu"))
return(model)
}
train_predict_lstm <- function(scaled_series, lag = 10L, horizon = 30L, epochs = 100, batch_size = 32) {
data <- create_lstm_data(scaled_series, lag)
X <- data$X
y <- data$y
model <- build_lstm_model(input_shape = c(lag, 1))
model$compile(
loss = "mean_squared_error",
optimizer = keras$optimizers$Adam()
)
early_stop <- callback_early_stopping(
monitor = "loss",
patience = 10,
restore_best_weights = TRUE
)
model$fit(
x = X,
y = y,
epochs = 100L,
batch_size = 32L,
callbacks = list(early_stop)
)
preds <- numeric(horizon)
last_seq <- tail(scaled_series, lag)
for (i in 1:horizon) {
input_seq <- array(last_seq, dim = c(1L, lag, 1L))
input_seq <- tf$cast(input_seq, dtype = tf$float32)
pred <- as.numeric(model$predict(input_seq))
preds[i] <- pred
last_seq <- c(last_seq[-1], pred)
}
return(preds)
}
#########################
# 3. Bắt đầu triển khai mô hình DLWR-LSTM
#########################
# Dữ liệu đầu vào
raw_series <- as.numeric(training_data$vnindex_close)
decomp <- DLWR_decompose(raw_series, spans = c(0.3, 0.3, 0.3), degree = 2)
# Số bước dự báo
forecast_horizon <- as.integer(nrow(test_data))
# Khởi tạo danh sách kết quả
preds_components <- list()
# Huấn luyện và dự báo từng thành phần DLWR bằng LSTM riêng
for (name in c("f0", "f1", "f2", "d2")) {
comp <- decomp[[name]]
scaled <- scale_minmax(comp)
pred_scaled <- train_predict_lstm(
scaled_series = scaled$scaled,
lag = 10L,
horizon = forecast_horizon,
epochs = 100,
batch_size = 32
)
preds_components[[name]] <- pred_scaled * (scaled$max - scaled$min) + scaled$min
}
tf <- tensorflow::tf
#########################
# 1. Hàm phân tách DLWR
#########################
DLWR_decompose <- function(R, spans = c(0.3, 0.3, 0.3), degree = 2) {
n <- length(R)
t <- seq_len(n)
fit_f0 <- loess(R ~ t, span = spans[1], degree = degree)
f0 <- predict(fit_f0, newdata = data.frame(t = t))
d0 <- R - f0
fit_f1 <- loess(d0 ~ t, span = spans[2], degree = degree)
f1 <- predict(fit_f1, newdata = data.frame(t = t))
d1 <- d0 - f1
fit_f2 <- loess(d1 ~ t, span = spans[3], degree = degree)
f2 <- predict(fit_f2, newdata = data.frame(t = t))
d2 <- d1 - f2
return(list(f0 = f0, f1 = f1, f2 = f2, d2 = d2))
}
#########################
# 2. Tiện ích hỗ trợ
#########################
scale_minmax <- function(x) {
min_x <- min(x, na.rm = TRUE)
max_x <- max(x, na.rm = TRUE)
scaled <- (x - min_x) / (max_x - min_x)
list(scaled = scaled, min = min_x, max = max_x)
}
create_lstm_data <- function(series, lag = 10L) {
n <- length(series)
num_samples <- n - lag
X <- array(NA, dim = c(num_samples, lag, 1))
y <- array(NA, dim = c(num_samples))
for (i in 1:num_samples) {
X[i, , 1] <- series[i:(i + lag - 1)]
y[i] <- series[i + lag]
}
list(X = X, y = y)
}
build_lstm_model <- function(input_shape = c(10L, 1L)) {
model <- keras_model_sequential()
model$add(layer_lstm(units = 64, input_shape = input_shape, return_sequences = TRUE))
model$add(layer_lstm(units = 128, return_sequences = TRUE))
model$add(layer_lstm(units = 128))
model$add(layer_dense(units = 128, activation = "relu"))
model$add(layer_dropout(rate = 0.2))
model$add(layer_dense(units = 1, activation = "relu"))
return(model)
}
train_predict_lstm <- function(scaled_series, lag = 10L, horizon = 30L, epochs = 100, batch_size = 32) {
data <- create_lstm_data(scaled_series, lag)
X <- data$X
y <- data$y
model <- build_lstm_model(input_shape = c(lag, 1))
model$compile(
loss = "mean_squared_error",
optimizer = keras$optimizers$Adam()
)
early_stop <- callback_early_stopping(
monitor = "loss",
patience = 10,
restore_best_weights = TRUE
)
model$fit(
x = X,
y = y,
epochs = 100L,
batch_size = 32L,
callbacks = list(early_stop)
)
preds <- numeric(horizon)
last_seq <- tail(scaled_series, lag)
for (i in 1:horizon) {
input_seq <- array(last_seq, dim = c(1L, lag, 1L))
input_seq <- tf$cast(input_seq, dtype = tf$float32)
pred <- as.numeric(model$predict(input_seq))
preds[i] <- pred
last_seq <- c(last_seq[-1], pred)
}
return(preds)
}
#########################
# 3. Bắt đầu triển khai mô hình DLWR-LSTM
#########################
# Dữ liệu đầu vào
raw_series <- as.numeric(training_data$vnindex_close)
decomp <- DLWR_decompose(raw_series, spans = c(0.3, 0.3, 0.3), degree = 2)
# Số bước dự báo
forecast_horizon <- as.integer(nrow(test_data))
# Khởi tạo danh sách kết quả
preds_components <- list()
# Huấn luyện và dự báo từng thành phần DLWR bằng LSTM riêng
for (name in c("f0", "f1", "f2", "d2")) {
comp <- decomp[[name]]
scaled <- scale_minmax(comp)
pred_scaled <- train_predict_lstm(
scaled_series = scaled$scaled,
lag = 10L,
horizon = forecast_horizon,
epochs = 100,
batch_size = 32
)
preds_components[[name]] <- pred_scaled * (scaled$max - scaled$min) + scaled$min
}
# Tổng hợp dự báo cuối cùng
final_forecast <- preds_components$f0 + preds_components$f1 + preds_components$f2 + preds_components$d2
#########################
# 4. Vẽ kết quả so với thực tế
#########################
actual <- as.numeric(test_data$vnindex_close)
forecast_dates <- index(test_data)
plot(forecast_dates, actual, type = "l", col = "blue", lwd = 2,
main = "Dự báo DLWR-LSTM với 4 thành phần",
xlab = "Ngày", ylab = "VN-Index",
ylim = range(c(actual, final_forecast)))
lines(forecast_dates, final_forecast, col = "red", lwd = 2)
legend("topleft", legend = c("Thực tế", "DLWR-LSTM Dự báo"),
col = c("blue", "red"), lty = 1, lwd = 2)
# Lưu kết quả
results[["LSTM_LWR"]] <- final_forecast
